{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn import random_projection\n",
    "sns.set_style(\"whitegrid\")\n",
    "np.random.seed(0)\n",
    "import platform"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NDRindex implementation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_distance(x1, x2):\n",
    "    \"\"\"\n",
    "    Computes the norm of the vector between x1 and x2\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(x2-x1)\n",
    "\n",
    "def get_distances_lower_quartile(dataset):\n",
    "    \"\"\"\n",
    "    Determines the lower quartile of the distances\n",
    "    \"\"\"\n",
    "    distances = []\n",
    "    for x1 in range(dataset.shape[0]-1):\n",
    "        for x2 in range(x1+1, dataset.shape[0]):\n",
    "            distances.append(get_distance(dataset[x1], dataset[x2]))\n",
    "    if len(distances)%4 == 0:\n",
    "        return sorted(distances)[len(distances)//4]\n",
    "    else:\n",
    "        return sum(sorted(distances)[len(distances)//4:len(distances)//4+1])/2\n",
    "\n",
    "def get_distances_matrix(dataset):\n",
    "    distances = np.zeros((dataset.shape[0], dataset.shape[0]))\n",
    "    for x1 in range(dataset.shape[0]):\n",
    "        for x2 in range(dataset.shape[0]):\n",
    "            distances[x1][x2] = get_distance(dataset[x1], dataset[x2])\n",
    "    return distances\n",
    "\n",
    "def get_average_scale(dataset):\n",
    "    return get_distances_lower_quartile(dataset)/(np.log10(dataset.shape[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_geometric_center(cluster, dim=2):\n",
    "    \"\"\"\n",
    "    Cluster is a list of points.\n",
    "    The geometric center is the mass center of the cluster, all the points having a mass of 1.\n",
    "    \"\"\"\n",
    "    return [np.sum(np.array(cluster)[:, i])/len(cluster) for i in range(dim)]\n",
    "\n",
    "def fill_clusters(dataset, dim=2):\n",
    "    K = 0\n",
    "    clusters = [[[], [0 for _ in range(dim)]]]\n",
    "\n",
    "    # Shuffle the points to access them in a random order\n",
    "    points = np.arange(0, dataset.shape[0], 1)\n",
    "    np.random.shuffle(points)\n",
    "    added_points = [points[0]]\n",
    "\n",
    "    # Initialize the first cluster\n",
    "    clusters[0][0].append(dataset[points[0]])\n",
    "    clusters[0][1] = dataset[points[0]]\n",
    "\n",
    "    Y = -1 * np.ones(dataset.shape[0])\n",
    "\n",
    "    # Define the average scale\n",
    "    average_scale = get_average_scale(dataset)\n",
    "\n",
    "    while len(added_points) < dataset.shape[0]:\n",
    "        minimal_distance = 10e10\n",
    "        point_to_add = -1\n",
    "        for p in points:\n",
    "            if p not in added_points:\n",
    "                distance = get_distance(dataset[p], clusters[K][1])\n",
    "                if distance < minimal_distance:\n",
    "                    minimal_distance = distance\n",
    "                    point_to_add = p\n",
    "        if minimal_distance <= average_scale:\n",
    "            clusters[K][0].append(dataset[point_to_add])\n",
    "            clusters[K][1] = get_geometric_center(clusters[K][0], dim=dim)\n",
    "        else:\n",
    "            K += 1\n",
    "            clusters.append([[dataset[point_to_add]], dataset[point_to_add]])\n",
    "        added_points.append(point_to_add)\n",
    "        Y[point_to_add] = K\n",
    "\n",
    "    # Return only the clusters\n",
    "    return np.array([np.array(c[0]) for c in clusters], dtype=object)\n",
    "\n",
    "def get_cluster_radius(cluster, dim=2):\n",
    "    geometric_center = get_geometric_center(cluster, dim=dim)\n",
    "    distances = [get_distance(cluster[i], geometric_center) for i in range(cluster.shape[0])]\n",
    "    return sum(distances)/len(distances)\n",
    "\n",
    "def get_R(clusters, dim=2):\n",
    "    return sum([get_cluster_radius(clusters[i], dim=dim) for i in range(clusters.shape[0])])/clusters.shape[0]\n",
    "\n",
    "def NDRIndex(dataset, it=100, dim=2):\n",
    "    res = 0\n",
    "    for _ in range(it):\n",
    "        clusters = fill_clusters(dataset, dim=dim)\n",
    "        res += 1 - get_R(clusters, dim=dim)/get_average_scale(dataset)\n",
    "    return res/it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing on real data\n",
    "## Loading of data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "count = pd.read_csv('mouse.csv')\n",
    "names = list(count)[1:]\n",
    "count_cells = count[names].to_numpy().T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Normalization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "normalized_arr = preprocessing.normalize(count_cells)\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "min_maxed_arr = scaler.fit_transform(count_cells)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dimension reduction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "pca2 = PCA(n_components=6)\n",
    "pca2.fit(normalized_arr)\n",
    "normalized_arr_pca = pca2.transform(normalized_arr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "pca3 = PCA(n_components=6)\n",
    "pca3.fit(min_maxed_arr)\n",
    "min_maxed_arr_pca = pca2.transform(min_maxed_arr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "svd2 = TruncatedSVD(n_components=2)\n",
    "svd2.fit(normalized_arr)\n",
    "normalized_arr_svd = svd2.transform(normalized_arr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "svd3 = TruncatedSVD(n_components=2)\n",
    "svd3.fit(min_maxed_arr)\n",
    "min_maxed_arr_svd = svd3.transform(min_maxed_arr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The four resulting NDRindex"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDRIndex for Normalize + PCA 0.9222784254824972\n",
      "NDRIndex for MinMax + PCA 0.8368102223950831\n",
      "NDRIndex for Normalize + SVD: 0.8883059904088145\n",
      "NDRIndex for MinMax + SVD: 0.8245921933315248\n"
     ]
    }
   ],
   "source": [
    "print(\"NDRIndex for Normalize + PCA\", NDRIndex(normalized_arr_pca[:100], dim=6))\n",
    "print(\"NDRIndex for MinMax + PCA\", NDRIndex(min_maxed_arr_pca[:100], dim=6))\n",
    "print(\"NDRIndex for Normalize + SVD:\", NDRIndex(normalized_arr_svd[:100], dim=2))\n",
    "print(\"NDRIndex for MinMax + SVD:\", NDRIndex(min_maxed_arr_svd [:100], dim=2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Clustering\n",
    "\n",
    "Metrics used:\n",
    "- silhouette (to max): \"The Silhouette Coefficient is defined for each sample and is composed of two scores: a: The mean distance between a sample and all other points in the same class. b: The mean distance between a sample and all other points in the next nearest cluster. The Silhouette Coefficient s for a single sample is then given as: s=(b-a)/max(a,b)\"\n",
    "- calinski harabaskz (to max): \"The index is the ratio of the sum of between-clusters dispersion and of within-cluster dispersion for all clusters (where dispersion is defined as the sum of distances squared)\"\n",
    "- davies bouldin (to min): \"This index signifies the average ‘similarity’ between clusters, where the similarity is a measure that compares the distance between clusters with the size of the clusters themselves.\"\n",
    "\n",
    "## KMeans"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans on Normalize + PCA: \n",
      "\n",
      "Silhouette: 0.7406977052894916\n",
      "Calinski Harabasz: 181.26081236253583\n",
      "Davies Bouldin: 0.38786362447025535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cha/PycharmProjects/NDRIndex/env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/cha/PycharmProjects/NDRIndex/env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/cha/PycharmProjects/NDRIndex/env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "df = normalized_arr_pca[:100]\n",
    "kmeans = KMeans(n_clusters = 3)\n",
    "res = np.array(kmeans.fit_predict(df))\n",
    "arr = np.insert(df, len(df[0]), res, axis=1)\n",
    "df = arr\n",
    "df = pd.DataFrame(arr, columns = ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'label'])\n",
    "\n",
    "print(\"KMeans on Normalize + PCA: \\n\")\n",
    "print(\"Silhouette: \" + str(metrics.silhouette_score(df[['C1', 'C2', 'C3', 'C4', 'C5', 'C6']], df[['label']], metric='euclidean')))\n",
    "print(\"Calinski Harabasz: \" + str(metrics.calinski_harabasz_score(df[['C1', 'C2', 'C3', 'C4', 'C5', 'C6']], df[['label']])))\n",
    "print(\"Davies Bouldin: \" + str(metrics.davies_bouldin_score(df[['C1', 'C2', 'C3', 'C4', 'C5', 'C6']], df[['label']])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans on MinMax + PCA: \n",
      "\n",
      "Silhouette: 0.5284162034412085\n",
      "Calinski Harabasz: 103.10315823154086\n",
      "Davies Bouldin: 0.7083797481553313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cha/PycharmProjects/NDRIndex/env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/cha/PycharmProjects/NDRIndex/env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/cha/PycharmProjects/NDRIndex/env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "df = min_maxed_arr_pca[:100]\n",
    "kmeans = KMeans(n_clusters = 3)\n",
    "res = np.array(kmeans.fit_predict(df))\n",
    "arr = np.insert(df, len(df[0]), res, axis=1)\n",
    "df = arr\n",
    "df = pd.DataFrame(arr, columns = ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'label'])\n",
    "\n",
    "print(\"KMeans on MinMax + PCA: \\n\")\n",
    "print(\"Silhouette: \" + str(metrics.silhouette_score(df[['C1', 'C2', 'C3', 'C4', 'C5', 'C6']], df[['label']], metric='euclidean')))\n",
    "print(\"Calinski Harabasz: \" + str(metrics.calinski_harabasz_score(df[['C1', 'C2', 'C3', 'C4', 'C5', 'C6']], df[['label']])))\n",
    "print(\"Davies Bouldin: \" + str(metrics.davies_bouldin_score(df[['C1', 'C2', 'C3', 'C4', 'C5', 'C6']], df[['label']])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans on Normalize + SVD\n",
      "Silhouette: 0.7681567169698973\n",
      "Calinski Harabasz: 1312.0210626412922\n",
      "Davies Bouldin: 0.38039978251738876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cha/PycharmProjects/NDRIndex/env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/cha/PycharmProjects/NDRIndex/env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/cha/PycharmProjects/NDRIndex/env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "df = normalized_arr_svd[:100]\n",
    "kmeans = KMeans(n_clusters = 3)\n",
    "res = np.array(kmeans.fit_predict(df))\n",
    "arr = np.insert(df, len(df[0]), res, axis=1)\n",
    "df = arr\n",
    "df = pd.DataFrame(arr, columns = ['C1', 'C2', 'label'])\n",
    "\n",
    "print(\"KMeans on Normalize + SVD\")\n",
    "print(\"Silhouette: \" + str(metrics.silhouette_score(df[['C1', 'C2']], df[['label']], metric='euclidean')))\n",
    "print(\"Calinski Harabasz: \" + str(metrics.calinski_harabasz_score(df[['C1', 'C2']], df[['label']])))\n",
    "print(\"Davies Bouldin: \" + str(metrics.davies_bouldin_score(df[['C1', 'C2']], df[['label']])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans on MinMax + SVD: \n",
      "\n",
      "Silhouette: 0.5373188166172057\n",
      "Calinski Harabasz: 99.31904094383715\n",
      "Davies Bouldin: 0.6137623707150898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cha/PycharmProjects/NDRIndex/env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/cha/PycharmProjects/NDRIndex/env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/cha/PycharmProjects/NDRIndex/env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "df = min_maxed_arr_svd[:100]\n",
    "kmeans = KMeans(n_clusters = 3)\n",
    "res = np.array(kmeans.fit_predict(df))\n",
    "arr = np.insert(df, len(df[0]), res, axis=1)\n",
    "df = arr\n",
    "df = pd.DataFrame(arr, columns = ['C1', 'C2', 'label'])\n",
    "\n",
    "print(\"KMeans on MinMax + SVD: \\n\")\n",
    "print(\"Silhouette: \" + str(metrics.silhouette_score(df[['C1', 'C2']], df[['label']], metric='euclidean')))\n",
    "print(\"Calinski Harabasz: \" + str(metrics.calinski_harabasz_score(df[['C1', 'C2']], df[['label']])))\n",
    "print(\"Davies Bouldin: \" + str(metrics.davies_bouldin_score(df[['C1', 'C2']], df[['label']])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Agglomerative clustering (hclust)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgglomerativeClustering on Normalize + PCA: \n",
      "\n",
      "Silhouette: 0.7377217960563341\n",
      "Calinski Harabasz: 179.66909793262775\n",
      "Davies Bouldin: 0.392446476723502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cha/PycharmProjects/NDRIndex/env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/cha/PycharmProjects/NDRIndex/env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/cha/PycharmProjects/NDRIndex/env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "hierarchical_cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
    "df = normalized_arr_pca[:100]\n",
    "labels = hierarchical_cluster.fit_predict(df)\n",
    "arr = np.insert(df, len(df[0]), np.array(labels), axis=1)\n",
    "df = pd.DataFrame(arr, columns = ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'label'])\n",
    "\n",
    "\n",
    "print(\"AgglomerativeClustering on Normalize + PCA: \\n\")\n",
    "print(\"Silhouette: \" + str(metrics.silhouette_score(df[['C1', 'C2', 'C3', 'C4', 'C5', 'C6']], df[['label']], metric='euclidean')))\n",
    "print(\"Calinski Harabasz: \" + str(metrics.calinski_harabasz_score(df[['C1', 'C2', 'C3', 'C4', 'C5', 'C6']], df[['label']])))\n",
    "print(\"Davies Bouldin: \" + str(metrics.davies_bouldin_score(df[['C1', 'C2', 'C3', 'C4', 'C5', 'C6']], df[['label']])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgglomerativeClustering on MinMax + PCA: \n",
      "\n",
      "Silhouette: 0.48748701926440857\n",
      "Calinski Harabasz: 87.03315959699071\n",
      "Davies Bouldin: 0.6903001421318624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cha/PycharmProjects/NDRIndex/env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/cha/PycharmProjects/NDRIndex/env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/cha/PycharmProjects/NDRIndex/env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "hierarchical_cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
    "df = min_maxed_arr_pca[:100]\n",
    "labels = hierarchical_cluster.fit_predict(df)\n",
    "arr = np.insert(df, len(df[0]), np.array(labels), axis=1)\n",
    "df = pd.DataFrame(arr, columns = ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'label'])\n",
    "\n",
    "print(\"AgglomerativeClustering on MinMax + PCA: \\n\")\n",
    "print(\"Silhouette: \" + str(metrics.silhouette_score(df[['C1', 'C2', 'C3', 'C4', 'C5', 'C6']], df[['label']], metric='euclidean')))\n",
    "print(\"Calinski Harabasz: \" + str(metrics.calinski_harabasz_score(df[['C1', 'C2', 'C3', 'C4', 'C5', 'C6']], df[['label']])))\n",
    "print(\"Davies Bouldin: \" + str(metrics.davies_bouldin_score(df[['C1', 'C2', 'C3', 'C4', 'C5', 'C6']], df[['label']])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgglomerativeClustering on Normalize + SVD: \n",
      "\n",
      "Silhouette: 0.7681567169698973\n",
      "Calinski Harabasz: 1312.0210626412922\n",
      "Davies Bouldin: 0.38039978251738876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cha/PycharmProjects/NDRIndex/env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/cha/PycharmProjects/NDRIndex/env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/cha/PycharmProjects/NDRIndex/env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "hierarchical_cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
    "df = normalized_arr_svd[:100]\n",
    "labels = hierarchical_cluster.fit_predict(df)\n",
    "arr = np.insert(df, len(df[0]), np.array(labels), axis=1)\n",
    "df = pd.DataFrame(arr, columns = ['C1', 'C2', 'label'])\n",
    "\n",
    "print(\"AgglomerativeClustering on Normalize + SVD: \\n\")\n",
    "print(\"Silhouette: \" + str(metrics.silhouette_score(df[['C1', 'C2']], df[['label']], metric='euclidean')))\n",
    "print(\"Calinski Harabasz: \" + str(metrics.calinski_harabasz_score(df[['C1', 'C2']], df[['label']])))\n",
    "print(\"Davies Bouldin: \" + str(metrics.davies_bouldin_score(df[['C1', 'C2']], df[['label']])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgglomerativeClustering on MinMax + SVD: \n",
      "\n",
      "Silhouette: 0.5501534725572896\n",
      "Calinski Harabasz: 97.3025874930417\n",
      "Davies Bouldin: 0.5994025521189621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cha/PycharmProjects/NDRIndex/env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/cha/PycharmProjects/NDRIndex/env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/cha/PycharmProjects/NDRIndex/env/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "hierarchical_cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
    "df = min_maxed_arr_svd[:100]\n",
    "labels = hierarchical_cluster.fit_predict(df)\n",
    "arr = np.insert(df, len(df[0]), np.array(labels), axis=1)\n",
    "df = pd.DataFrame(arr, columns = ['C1', 'C2', 'label'])\n",
    "\n",
    "print(\"AgglomerativeClustering on MinMax + SVD: \\n\")\n",
    "print(\"Silhouette: \" + str(metrics.silhouette_score(df[['C1', 'C2']], df[['label']], metric='euclidean')))\n",
    "print(\"Calinski Harabasz: \" + str(metrics.calinski_harabasz_score(df[['C1', 'C2']], df[['label']])))\n",
    "print(\"Davies Bouldin: \" + str(metrics.davies_bouldin_score(df[['C1', 'C2']], df[['label']])))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
